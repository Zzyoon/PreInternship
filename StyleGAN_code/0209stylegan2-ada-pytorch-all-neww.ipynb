{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0209stylegan2-ada-pytorch-all-neww.ipynb","provenance":[{"file_id":"https://github.com/derekphilipau/machinelearningforartists/blob/main/stylegan2_ada_pytorch_all_new5.ipynb","timestamp":1644332781997}],"collapsed_sections":["wD9Cb5OUIwuw"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zd2p_MwDv2ji"},"source":["# SETUP (MUST RUN EACH TIME)"]},{"cell_type":"markdown","metadata":{"id":"oLqHshr2y-MO"},"source":["## Verify Runtime is GPU\n","\n","In the menu, select Runtime -> Change Runtime Type and verify you are using the **GPU**.  Also select **High-RAM** if you are using Colab Pro.\n","\n","The `nvidia-smi` command below should **NOT** display *\"NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver.\"*"]},{"cell_type":"code","metadata":{"id":"R7JvPMLWy95f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"10427f5f-3fbe-41b1-c544-16650ac9cf6c","executionInfo":{"status":"ok","timestamp":1644471176986,"user_tz":-540,"elapsed":39,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!nvidia-smi -L"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla K80 (UUID: GPU-09fcda22-e9ad-6552-57f0-5e9a1f215e6f)\n"]}]},{"cell_type":"markdown","metadata":{"id":"WUl3Rt0ryX7m"},"source":["## Mount your Google Drive\n","\n","You will be storing the training models and progress images on your Google Drive.  This is very convenient for viewing progress, and if your Colab notebook is disconnected you will not lose your models."]},{"cell_type":"code","metadata":{"id":"Ag2Bb1pPzthT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471203768,"user_tz":-540,"elapsed":26798,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"e4d571fb-5641-4df8-fd9f-ef6fb8d323b2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"JIHuj2eEy13f"},"source":["## Install Stylegan2-ada-pytorch Prerequisites"]},{"cell_type":"code","metadata":{"id":"A8r0Ca7Hpo5F","executionInfo":{"status":"ok","timestamp":1644471220047,"user_tz":-540,"elapsed":5540,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["import torch"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2y195-nOz19D"},"source":["Verify the next command results in \"1\".  If not, go back to the beginning and verify you have a GPU runtime."]},{"cell_type":"code","metadata":{"id":"KV07xnKTprut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471220048,"user_tz":-540,"elapsed":10,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"fdd2f091-81f4-47ad-d4a9-25b6b6bd0d68"},"source":["torch.cuda.device_count()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"6jY44x99pusN","executionInfo":{"status":"ok","timestamp":1644471220452,"user_tz":-540,"elapsed":412,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["import torchvision"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZhoCdj4pREI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471228541,"user_tz":-540,"elapsed":8103,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"654ccd09-f5d6-45d9-90d0-763e30dbacc2"},"source":["!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Collecting pyspng\n","  Downloading pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195 kB)\n","\u001b[K     |████████████████████████████████| 195 kB 12.7 MB/s \n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 50.6 MB/s \n","\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n","  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[K     |████████████████████████████████| 26.9 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.19.5)\n","Installing collected packages: pyspng, ninja, imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.4.3 ninja-1.10.2.3 pyspng-0.1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"b94le1Kh_v1k"},"source":["## Get the StyleGAN code"]},{"cell_type":"code","metadata":{"id":"najHDP7gMeFy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644388675368,"user_tz":-540,"elapsed":1398,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"20ef6898-2971-43ee-dbcd-57c3daf4bf02"},"source":["# WARNING : conv2d_gradfix not supported on PyTorch {torch.__version__}.\n","# !git clone https://github.com/derekphilipau/stylegan2-ada-pytorch.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stylegan2-ada-pytorch'...\n","remote: Enumerating objects: 128, done.\u001b[K\n","remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n","Receiving objects: 100% (128/128), 1.12 MiB | 2.85 MiB/s, done.\n","Resolving deltas: 100% (58/58), done.\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/snoop2head/stylegan2-ada-pytorch.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOf5TzOGehjQ","executionInfo":{"status":"ok","timestamp":1644471229044,"user_tz":-540,"elapsed":536,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"fb5cdd0f-1b13-4631-a139-5222c2fac698"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stylegan2-ada-pytorch'...\n","remote: Enumerating objects: 134, done.\u001b[K\n","remote: Total 134 (delta 0), reused 0 (delta 0), pack-reused 134\u001b[K\n","Receiving objects: 100% (134/134), 1.12 MiB | 20.51 MiB/s, done.\n","Resolving deltas: 100% (62/62), done.\n"]}]},{"cell_type":"code","metadata":{"id":"GCYmJ2Z60WSe","executionInfo":{"status":"ok","timestamp":1644471229521,"user_tz":-540,"elapsed":16,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["mkdir /content/stylegan2-ada-pytorch/datasets"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRwQwWc9RNAD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471231708,"user_tz":-540,"elapsed":15,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"58dc40f4-27fb-42a3-e9e3-9b7ab794e4b3"},"source":["%cd /content/stylegan2-ada-pytorch"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch\n"]}]},{"cell_type":"markdown","metadata":{"id":"GDAf0tWzv-8J"},"source":["# FIRST RUN (RUN ONLY ONCE)"]},{"cell_type":"markdown","metadata":{"id":"QTo4K3m8AEzh"},"source":["## Create Folders on Your Google Drive\n","\n","If we accidentally close our browser or the Colab runtime disconnects, we will lose all of our training models and progress images.  Therefore we want to store the training data on our Google Drive.  The following cells will create a new folder on your Google Drive, **MachineLearningForArtists**.  Your training data will be stored in **MachineLearningForArtists/MyProject**"]},{"cell_type":"code","metadata":{"id":"MexWxMvLHP5O"},"source":["mkdir /content/drive/MyDrive/MachineLearningForArtists"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tja3AaYIHU9v"},"source":["mkdir /content/drive/MyDrive/MachineLearningForArtists/Ghibli3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpk9vGb50lee"},"source":["## Prepare Your Image Dataset for StyleGAN\n"]},{"cell_type":"markdown","metadata":{"id":"wD9Cb5OUIwuw"},"source":["### Unzip your dataset\n","\n","***If your images are not zipped, skip this step.***\n","\n","If your images are in a .zip file, you will need to unzip them.   Copy the path to your .zip file and paste here under `zip_path`. \n"]},{"cell_type":"code","metadata":{"cellView":"form","id":"yckdAoWWI8Al"},"source":["zip_path = '/content/resize_square-20220208T134536Z-001.zip' #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcMEv7XdIwBu"},"source":["!unzip \"$zip_path\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K9q_opWqJh8y"},"source":["### Prepare your dataset for StyleGAN\n"]},{"cell_type":"markdown","metadata":{"id":"k-L7EeWNJq2V"},"source":["Copy the path to your unzipped dataset folder of images and paste into `dataset_path`"]},{"cell_type":"code","metadata":{"id":"QUQKuQVBInqo","cellView":"form","executionInfo":{"status":"ok","timestamp":1644471237982,"user_tz":-540,"elapsed":585,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["dataset_path = '/content/drive/MyDrive/resize_square' #@param {type:\"string\"}"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRRzr1rCPdHc"},"source":["The following commands will prepare your dataset.  It will crop all of your images to 512x512 pixels.  ***It will NOT overwrite your original images.***"]},{"cell_type":"code","metadata":{"id":"3XJdao4Pn9zP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471254805,"user_tz":-540,"elapsed":16438,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"d1b8c90c-a250-4316-e53d-480c3448f581"},"source":["!apt install imagemagick webp"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages were automatically installed and are no longer required:\n","  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n","  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n","  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n","  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n","  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n","  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n","  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n","  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n","  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n","  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n","  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n","  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n","  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n","  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n","  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n","  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n","  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n","  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n","  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n","  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n","  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n","  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n","  cuda-visual-tools-11-1 default-jre dkms freeglut3-dev keyboard-configuration\n","  libargon2-0 libcap2 libcryptsetup12 libdevmapper1.02.1 libfontenc1 libip4tc0\n","  libjansson4 libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n","  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n","  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n","  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n","  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n","  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n","  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n","  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n","  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n","  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n","Use 'apt autoremove' to remove them.\n","The following additional packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","Suggested packages:\n","  fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr | lprng\n","  enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray radiance\n","  sane-utils texlive-base-bin transfig ufraw-batch inkscape libjxr-tools\n","  libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n","  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n","  fonts-arphic-uming fonts-nanum\n","The following NEW packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts imagemagick\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data webp\n","0 upgraded, 24 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 18.5 MB of archives.\n","After this operation, 66.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.12 [60.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [1,621 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [292 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.15 [5,092 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [2,265 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [51.4 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [423 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [14.2 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.4 [49.4 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.4 [561 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [62.4 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnetpbm10 amd64 2:10.0-15.3build1 [58.0 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 netpbm amd64 2:10.0-15.3build1 [1,017 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 webp amd64 0.6.1-2ubuntu0.18.04.1 [78.5 kB]\n","Fetched 18.5 MB in 0s (47.8 MB/s)\n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 155113 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Selecting previously unselected package liblqr-1-0:amd64.\n","Preparing to unpack .../01-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n","Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Selecting previously unselected package imagemagick-6-common.\n","Preparing to unpack .../02-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n","Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n","Preparing to unpack .../03-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n","Preparing to unpack .../04-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../05-poppler-data_0.4.8-2_all.deb ...\n","Unpacking poppler-data (0.4.8-2) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../06-fonts-noto-mono_20171026-2_all.deb ...\n","Unpacking fonts-noto-mono (20171026-2) ...\n","Selecting previously unselected package libcupsimage2:amd64.\n","Preparing to unpack .../07-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n","Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../08-libijs-0.35_0.35-13_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-13) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../09-libjbig2dec0_0.13-6_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.13-6) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../10-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.15_all.deb ...\n","Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../11-libgs9_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n","Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Selecting previously unselected package ghostscript.\n","Preparing to unpack .../12-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n","Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Selecting previously unselected package gsfonts.\n","Preparing to unpack .../13-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n","Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Selecting previously unselected package imagemagick-6.q16.\n","Preparing to unpack .../14-imagemagick-6.q16_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package imagemagick.\n","Preparing to unpack .../15-imagemagick_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking imagemagick (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libcupsfilters1:amd64.\n","Preparing to unpack .../16-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n","Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Selecting previously unselected package libdjvulibre-text.\n","Preparing to unpack .../17-libdjvulibre-text_3.5.27.1-8ubuntu0.4_all.deb ...\n","Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libdjvulibre21:amd64.\n","Preparing to unpack .../18-libdjvulibre21_3.5.27.1-8ubuntu0.4_amd64.deb ...\n","Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libwmf0.2-7:amd64.\n","Preparing to unpack .../19-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n","Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n","Preparing to unpack .../20-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libnetpbm10.\n","Preparing to unpack .../21-libnetpbm10_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking libnetpbm10 (2:10.0-15.3build1) ...\n","Selecting previously unselected package netpbm.\n","Preparing to unpack .../22-netpbm_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking netpbm (2:10.0-15.3build1) ...\n","Selecting previously unselected package webp.\n","Preparing to unpack .../23-webp_0.6.1-2ubuntu0.18.04.1_amd64.deb ...\n","Unpacking webp (0.6.1-2ubuntu0.18.04.1) ...\n","Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Setting up poppler-data (0.4.8-2) ...\n","Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Setting up libnetpbm10 (2:10.0-15.3build1) ...\n","Setting up fonts-noto-mono (20171026-2) ...\n","Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Setting up libjbig2dec0:amd64 (0.13-6) ...\n","Setting up libijs-0.35:amd64 (0.35-13) ...\n","Setting up netpbm (2:10.0-15.3build1) ...\n","Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Setting up webp (0.6.1-2ubuntu0.18.04.1) ...\n","Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n","Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n","Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up imagemagick (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","metadata":{"id":"cD_RgCE1lypb","executionInfo":{"status":"ok","timestamp":1644471254806,"user_tz":-540,"elapsed":22,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!mkdir /content/stylegan2-ada-pytorch/datasets/raw"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdnhnLK9g9sw","executionInfo":{"status":"ok","timestamp":1644471254807,"user_tz":-540,"elapsed":19,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!mkdir /content/stylegan2-ada-pytorch/datasets/processed"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKig-ozwllZl","executionInfo":{"status":"ok","timestamp":1644471260651,"user_tz":-540,"elapsed":5860,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!cp \"$dataset_path\"/* /content/stylegan2-ada-pytorch/datasets/raw/"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFr2noZUndZl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471260653,"user_tz":-540,"elapsed":26,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"45cbd1d9-f149-4221-ba19-a619a6f41a58"},"source":["%cd /content/stylegan2-ada-pytorch/datasets/raw/"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch/datasets/raw\n"]}]},{"cell_type":"code","metadata":{"id":"tTa3LDLCo0x4","executionInfo":{"status":"ok","timestamp":1644471271765,"user_tz":-540,"elapsed":11130,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!mogrify -type TrueColor -set colorspace sRGB -colorspace sRGB -resize 512x512 -background white -gravity center -extent 512x512 -format jpg -path ../processed *"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBg2Zy06dkqz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471271766,"user_tz":-540,"elapsed":35,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"084aa545-e40f-4db8-a043-db8ff6f81772"},"source":["cd /content/stylegan2-ada-pytorch/"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch\n"]}]},{"cell_type":"code","metadata":{"id":"_szXOaO0WI00","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471275710,"user_tz":-540,"elapsed":3958,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"20690b12-7fae-4ce5-dddf-980a2d367c46"},"source":["!python dataset_tool.py --source=/content/stylegan2-ada-pytorch/datasets/raw/ --dest=./datasets/stylegan_dataset.zip"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 460/460 [00:03<00:00, 125.79it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"BJA-bph7vJbj","executionInfo":{"status":"ok","timestamp":1644471277620,"user_tz":-540,"elapsed":1923,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["!cp ./datasets/stylegan_dataset.zip /content/drive/MyDrive/MachineLearningForArtists/Ghibli3/"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OS14PMAY6SUW"},"source":["If you get an error \"cannot create directory\", it's probably because the folder already exists on your Google Drive and you can ignore the error."]},{"cell_type":"markdown","metadata":{"id":"HpR6A_qBAo8m"},"source":["## Train from Scratch\n","\n","This cell block will train StyleGAN from scratch.  Training from scratch is much slower than using *transfer learning* on a previously trained model.  However, the purpose of this tutorial is to a) try training for the first time and b) notice how the progress images develop over time."]},{"cell_type":"code","metadata":{"id":"NuSkETl1V8pv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644401839022,"user_tz":-540,"elapsed":71825,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"4addab04-1ce1-4e4a-be65-bf0b38087b7e"},"source":["!python train.py --outdir=/content/drive/MyDrive/MachineLearningForArtists/Ghibli3 --data=./datasets/stylegan_dataset.zip --gpus=1 --cfg=paper512 --mirror=1 --snap=10 --metrics=none\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 10,\n","  \"network_snapshot_ticks\": 10,\n","  \"metrics\": [],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"./datasets/stylegan_dataset.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 460,\n","    \"xflip\": true,\n","    \"resolution\": 256\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 8\n","    },\n","    \"synthesis_kwargs\": {\n","      \"channel_base\": 32768,\n","      \"channel_max\": 512,\n","      \"num_fp16_res\": 4,\n","      \"conv_clamp\": 256\n","    }\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 8\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 0.5\n","  },\n","  \"total_kimg\": 25000,\n","  \"batch_size\": 64,\n","  \"batch_gpu\": 8,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": null,\n","  \"ada_target\": 0.6,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"run_dir\": \"/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00000-stylegan_dataset-mirror-paper512\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00000-stylegan_dataset-mirror-paper512\n","Training data:      ./datasets/stylegan_dataset.zip\n","Training duration:  25000 kimg\n","Number of GPUs:     1\n","Number of images:   460\n","Image resolution:   256\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","Num images:  920\n","Image shape: [3, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Generator             Parameters  Buffers  Output shape        Datatype\n","---                   ---         ---      ---                 ---     \n","mapping.fc0           262656      -        [8, 512]            float32 \n","mapping.fc1           262656      -        [8, 512]            float32 \n","mapping.fc2           262656      -        [8, 512]            float32 \n","mapping.fc3           262656      -        [8, 512]            float32 \n","mapping.fc4           262656      -        [8, 512]            float32 \n","mapping.fc5           262656      -        [8, 512]            float32 \n","mapping.fc6           262656      -        [8, 512]            float32 \n","mapping.fc7           262656      -        [8, 512]            float32 \n","mapping               -           512      [8, 14, 512]        float32 \n","synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 \n","synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 \n","synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 \n","synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 \n","synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 \n","synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 \n","synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 \n","synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 \n","synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 \n","synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 \n","synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 \n","synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 \n","synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 \n","synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 \n","synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float16 \n","synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float16 \n","synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float16 \n","synthesis.b32:0       -           16       [8, 512, 32, 32]    float16 \n","synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 \n","synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 \n","synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 \n","synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 \n","synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 \n","synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 \n","synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 \n","synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 \n","synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 \n","synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 \n","synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 \n","synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 \n","synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 \n","synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 \n","synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 \n","synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 \n","---                   ---         ---      ---                 ---     \n","Total                 30034338    175568   -                   -       \n","\n","\n","Discriminator  Parameters  Buffers  Output shape        Datatype\n","---            ---         ---      ---                 ---     \n","b256.fromrgb   512         16       [8, 128, 256, 256]  float16 \n","b256.skip      32768       16       [8, 256, 128, 128]  float16 \n","b256.conv0     147584      16       [8, 128, 256, 256]  float16 \n","b256.conv1     295168      16       [8, 256, 128, 128]  float16 \n","b256           -           16       [8, 256, 128, 128]  float16 \n","b128.skip      131072      16       [8, 512, 64, 64]    float16 \n","b128.conv0     590080      16       [8, 256, 128, 128]  float16 \n","b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \n","b128           -           16       [8, 512, 64, 64]    float16 \n","b64.skip       262144      16       [8, 512, 32, 32]    float16 \n","b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \n","b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \n","b64            -           16       [8, 512, 32, 32]    float16 \n","b32.skip       262144      16       [8, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [8, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [8, 512, 16, 16]    float16 \n","b32            -           16       [8, 512, 16, 16]    float16 \n","b16.skip       262144      16       [8, 512, 8, 8]      float32 \n","b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \n","b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \n","b16            -           16       [8, 512, 8, 8]      float32 \n","b8.skip        262144      16       [8, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \n","b8             -           16       [8, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [8, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [8, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [8, 512]            float32 \n","b4.out         513         -        [8, 1]              float32 \n","---            ---         ---      ---                 ---     \n","Total          28864129    416      -                   -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.1      time 3m 45s       sec/tick 88.9    sec/kimg 1389.81 maintenance 136.2  cpumem 5.17   gpumem 9.32   augment 0.000\n","tick 1     kimg 4.1      time 48m 02s      sec/tick 2614.3  sec/kimg 648.38  maintenance 42.3   cpumem 5.42   gpumem 6.15   augment 0.005\n","tick 2     kimg 8.1      time 1h 32m 06s   sec/tick 2644.7  sec/kimg 655.93  maintenance 0.0    cpumem 5.42   gpumem 6.16   augment 0.009\n","tick 3     kimg 12.2     time 2h 16m 15s   sec/tick 2648.1  sec/kimg 656.76  maintenance 0.8    cpumem 5.42   gpumem 6.16   augment 0.016\n","\n","Aborted!\n"]}]},{"cell_type":"markdown","metadata":{"id":"NQVRH5rr4dki"},"source":["## Go to bed :)\n","\n","Normal training of a dataset can take days.\n","\n","Results are stored in your Google Drive under drive/MyDrive/MachineLearningForArtists/MyProject\n","\n","Each training run is stored in a separate directory.  The initial training run is stored in `00000-stylegan_dataset...`.  If you run training twice, the second run will be stored in `00001-stylegan_dataset...`.  And so on.\n","\n","Inside the training run directory you will see various files.  `reals.png` shows a sample of the training dataset.  In it you should see various images from your original dataset. `fakes000000.png` is a sample of generated images from the initial model.  `network-snapshot-XXXXXX.pkl` is the actual model which can be used later to generate \"fake\" images, videos, etc.\n","\n","As training progresses you will see more `fakes` & `network-snapshot` files created.\n"]},{"cell_type":"markdown","metadata":{"id":"zRG9NlIXwI7S"},"source":["# RESUME TRAINING\n","\n","***Make sure you run the above section \"SETUP (MUST RUN EACH TIME)\" before resuming training.***\n"]},{"cell_type":"code","metadata":{"id":"_aIf9TDOvloK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644417117479,"user_tz":-540,"elapsed":303,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"9789e3e4-f1eb-4ca9-b9c4-52f750cb4e70"},"source":["%cd /content/stylegan2-ada-pytorch"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch\n"]}]},{"cell_type":"markdown","metadata":{"id":"e6RnMcgvwQer"},"source":["Copy previously saved datset"]},{"cell_type":"code","metadata":{"id":"Jzi79zpLvQqI"},"source":["!cp /content/drive/MyDrive/MachineLearningForArtists/Ghibli3/stylegan_dataset.zip ./datasets/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7DtT8Dd-drmh"},"source":["If you had to stop training, the browser window closed, or the Colab session timed out (12-24 hours), you can resume training by using a .pkl file stored on your Google Drive.  For your project, this file will be in `drive/MyDrive/MachineLearningForArtists/MyProject/0000X-stylegan_datset...`"]},{"cell_type":"code","metadata":{"id":"Y-mxVLR_d8Sn","cellView":"form","executionInfo":{"status":"ok","timestamp":1644471291607,"user_tz":-540,"elapsed":378,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}}},"source":["#@title PKL File Path \n","#@markdown Copy & Paste .pkl file path here:\n","pkl_file = '/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00000-stylegan_dataset-mirror-paper512/network-snapshot-000000.pkl' #@param {type:\"string\"}\n"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-5Eyr6AjLh3"},"source":["Run the training, resuming with the last save .pkl file.  Results will be stored in your Google Drive under `MachineLearningForArtists/MyProject`"]},{"cell_type":"code","metadata":{"id":"eLR4E3HGvYe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471296414,"user_tz":-540,"elapsed":380,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"bfbb13a8-3396-4e0d-cd27-16f1fd54a9ce"},"source":["cd /content/stylegan2-ada-pytorch/"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch\n"]}]},{"cell_type":"code","metadata":{"id":"5V5YcgzBfcv2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644407456627,"user_tz":-540,"elapsed":51079,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"4916280a-2487-404d-a4b7-12eba4941b46"},"source":["!python train.py --resume=$pkl_file --outdir=/content/drive/MyDrive/MachineLearningForArtists/Ghibli3 --data=./datasets/stylegan_dataset.zip --gpus=1 --cfg=paper512 --mirror=1 --snap=10 --metrics=none\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 10,\n","  \"network_snapshot_ticks\": 10,\n","  \"metrics\": [],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"./datasets/stylegan_dataset.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 460,\n","    \"xflip\": true,\n","    \"resolution\": 256\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 8\n","    },\n","    \"synthesis_kwargs\": {\n","      \"channel_base\": 32768,\n","      \"channel_max\": 512,\n","      \"num_fp16_res\": 4,\n","      \"conv_clamp\": 256\n","    }\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 8\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 0.5\n","  },\n","  \"total_kimg\": 25000,\n","  \"batch_size\": 64,\n","  \"batch_gpu\": 8,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": null,\n","  \"ada_target\": 0.6,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"resume_pkl\": \"/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00000-stylegan_dataset-mirror-paper512/network-snapshot-000000.pkl\",\n","  \"ada_kimg\": 100,\n","  \"run_dir\": \"/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00001-stylegan_dataset-mirror-paper512-resumecustom\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00001-stylegan_dataset-mirror-paper512-resumecustom\n","Training data:      ./datasets/stylegan_dataset.zip\n","Training duration:  25000 kimg\n","Number of GPUs:     1\n","Number of images:   460\n","Image resolution:   256\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","Num images:  920\n","Image shape: [3, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Resuming from \"/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00000-stylegan_dataset-mirror-paper512/network-snapshot-000000.pkl\"\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Generator             Parameters  Buffers  Output shape        Datatype\n","---                   ---         ---      ---                 ---     \n","mapping.fc0           262656      -        [8, 512]            float32 \n","mapping.fc1           262656      -        [8, 512]            float32 \n","mapping.fc2           262656      -        [8, 512]            float32 \n","mapping.fc3           262656      -        [8, 512]            float32 \n","mapping.fc4           262656      -        [8, 512]            float32 \n","mapping.fc5           262656      -        [8, 512]            float32 \n","mapping.fc6           262656      -        [8, 512]            float32 \n","mapping.fc7           262656      -        [8, 512]            float32 \n","mapping               -           512      [8, 14, 512]        float32 \n","synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 \n","synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 \n","synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 \n","synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 \n","synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 \n","synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 \n","synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 \n","synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 \n","synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 \n","synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 \n","synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 \n","synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 \n","synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 \n","synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 \n","synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float16 \n","synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float16 \n","synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float16 \n","synthesis.b32:0       -           16       [8, 512, 32, 32]    float16 \n","synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 \n","synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 \n","synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 \n","synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 \n","synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 \n","synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 \n","synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 \n","synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 \n","synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 \n","synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 \n","synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 \n","synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 \n","synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 \n","synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 \n","synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 \n","synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 \n","---                   ---         ---      ---                 ---     \n","Total                 30034338    175568   -                   -       \n","\n","\n","Discriminator  Parameters  Buffers  Output shape        Datatype\n","---            ---         ---      ---                 ---     \n","b256.fromrgb   512         16       [8, 128, 256, 256]  float16 \n","b256.skip      32768       16       [8, 256, 128, 128]  float16 \n","b256.conv0     147584      16       [8, 128, 256, 256]  float16 \n","b256.conv1     295168      16       [8, 256, 128, 128]  float16 \n","b256           -           16       [8, 256, 128, 128]  float16 \n","b128.skip      131072      16       [8, 512, 64, 64]    float16 \n","b128.conv0     590080      16       [8, 256, 128, 128]  float16 \n","b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \n","b128           -           16       [8, 512, 64, 64]    float16 \n","b64.skip       262144      16       [8, 512, 32, 32]    float16 \n","b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \n","b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \n","b64            -           16       [8, 512, 32, 32]    float16 \n","b32.skip       262144      16       [8, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [8, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [8, 512, 16, 16]    float16 \n","b32            -           16       [8, 512, 16, 16]    float16 \n","b16.skip       262144      16       [8, 512, 8, 8]      float32 \n","b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \n","b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \n","b16            -           16       [8, 512, 8, 8]      float32 \n","b8.skip        262144      16       [8, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \n","b8             -           16       [8, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [8, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [8, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [8, 512]            float32 \n","b4.out         513         -        [8, 1]              float32 \n","---            ---         ---      ---                 ---     \n","Total          28864129    416      -                   -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.1      time 2m 47s       sec/tick 88.1    sec/kimg 1376.12 maintenance 78.7   cpumem 5.78   gpumem 9.32   augment 0.000\n","tick 1     kimg 4.1      time 47m 20s      sec/tick 2631.6  sec/kimg 652.68  maintenance 41.2   cpumem 5.71   gpumem 6.15   augment 0.026\n","\n","Aborted!\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZpOwAUvJwoiY"},"source":["# OPTIONAL: TRANSFER LEARNING"]},{"cell_type":"markdown","metadata":{"id":"RJ-xirKuHKEP"},"source":["## OR Use Transfer Learning (Optional)\n","\n","We don't have to train from scratch.  We can train using *transfer learning*.  We will use a StyleGAN2 model already pre-trained on faces to train a new model that is trained against our image dataset."]},{"cell_type":"markdown","metadata":{"id":"RM9mywxwPy8k"},"source":["### Get the faces model"]},{"cell_type":"code","metadata":{"id":"V9pbaodn8LKY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471304704,"user_tz":-540,"elapsed":457,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"8233da7c-74b2-411e-9553-c136296d22c3"},"source":["%cd /content/stylegan2-ada-pytorch"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada-pytorch\n"]}]},{"cell_type":"code","metadata":{"id":"lk-HFAMY7pke"},"source":["!apt-get install megatools"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["다운로드 ffhq-512-avg-tpurun1.pkl \n"],"metadata":{"id":"XE-JLmo86AFq"}},{"cell_type":"code","metadata":{"id":"Pm3cBBuTO4rC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471341735,"user_tz":-540,"elapsed":27593,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"dd56b5a4-bd39-4527-c8d7-85ffeda7fd5a"},"source":["!megadl https://mega.nz/#!eQdHkShY!8wyNKs343L7YUjwXlEg3cWjqK2g2EAIdYz5xbkPy3ng"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0KDownloaded ffhq-512-avg-tpurun1.pkl\n"]}]},{"cell_type":"markdown","metadata":{"id":"_97n-cE59QX_"},"source":["### Prepare old Faces model for StyleGAN2-ada-pytorch\n"]},{"cell_type":"markdown","source":["source파일을 dest파일로 복사"],"metadata":{"id":"BsADuXCVNcnp"}},{"cell_type":"code","metadata":{"id":"VZRzt2aH9WJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471354798,"user_tz":-540,"elapsed":2884,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"1f509227-1d89-40f7-e90b-2eb0515de006"},"source":["!python legacy.py \\\n","    --source=/content/stylegan2-ada-pytorch/ffhq-512-avg-tpurun1.pkl \\\n","    --dest=stylegan2-ada-pytorch-ffhq-512.pkl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading \"/content/stylegan2-ada-pytorch/ffhq-512-avg-tpurun1.pkl\"...\n","Traceback (most recent call last):\n","  File \"legacy.py\", line 318, in <module>\n","    convert_network_pickle() # pylint: disable=no-value-for-parameter\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n","    return self.main(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n","    rv = self.invoke(ctx)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n","    return ctx.invoke(self.callback, **ctx.params)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n","    return callback(*args, **kwargs)\n","  File \"legacy.py\", line 309, in convert_network_pickle\n","    data = load_network_pkl(f, force_fp16=force_fp16)\n","  File \"legacy.py\", line 26, in load_network_pkl\n","    G = convert_tf_generator(tf_G)\n","  File \"legacy.py\", line 155, in convert_tf_generator\n","    raise ValueError('Unknown TensorFlow kwarg', unknown_kwargs[0])\n","ValueError: ('Unknown TensorFlow kwarg', 'resolution_w')\n"]}]},{"cell_type":"markdown","metadata":{"id":"bUbn23OUQIS7"},"source":["### Train using the faces model with your dataset "]},{"cell_type":"code","metadata":{"id":"nIqAPSgaHKEZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644471773056,"user_tz":-540,"elapsed":12247,"user":{"displayName":"양지윤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01371122750861394767"}},"outputId":"242d1ed9-db2a-4603-cdc7-5f8ff30f2bde"},"source":["!python train.py --resume=/content/stylegan2-ada-pytorch/stylegan2-ada-pytorch-ffhq-512.pkl --outdir=/content/drive/MyDrive/MachineLearningForArtists/Ghibli3 --data=./datasets/stylegan_dataset.zip --gpus=1 --cfg=paper512 --mirror=1 --snap=10 --metrics=none\n"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 10,\n","  \"network_snapshot_ticks\": 10,\n","  \"metrics\": [],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"./datasets/stylegan_dataset.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 460,\n","    \"xflip\": true,\n","    \"resolution\": 256\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 8\n","    },\n","    \"synthesis_kwargs\": {\n","      \"channel_base\": 32768,\n","      \"channel_max\": 512,\n","      \"num_fp16_res\": 4,\n","      \"conv_clamp\": 256\n","    }\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 8\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 0.5\n","  },\n","  \"total_kimg\": 25000,\n","  \"batch_size\": 64,\n","  \"batch_gpu\": 8,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": null,\n","  \"ada_target\": 0.6,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"resume_pkl\": \"/content/stylegan2-ada-pytorch/ffhq-512-avg-tpurun1.pkl\",\n","  \"ada_kimg\": 100,\n","  \"run_dir\": \"/content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00005-stylegan_dataset-mirror-paper512-resumecustom\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/MachineLearningForArtists/Ghibli3/00005-stylegan_dataset-mirror-paper512-resumecustom\n","Training data:      ./datasets/stylegan_dataset.zip\n","Training duration:  25000 kimg\n","Number of GPUs:     1\n","Number of images:   460\n","Image resolution:   256\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","Num images:  920\n","Image shape: [3, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Resuming from \"/content/stylegan2-ada-pytorch/ffhq-512-avg-tpurun1.pkl\"\n","Traceback (most recent call last):\n","  File \"train.py\", line 538, in <module>\n","    main() # pylint: disable=no-value-for-parameter\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n","    return self.main(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n","    rv = self.invoke(ctx)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n","    return ctx.invoke(self.callback, **ctx.params)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n","    return callback(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/decorators.py\", line 21, in new_func\n","    return f(get_current_context(), *args, **kwargs)\n","  File \"train.py\", line 531, in main\n","    subprocess_fn(rank=0, args=args, temp_dir=temp_dir)\n","  File \"train.py\", line 383, in subprocess_fn\n","    training_loop.training_loop(rank=rank, **args)\n","  File \"/content/stylegan2-ada-pytorch/training/training_loop.py\", line 158, in training_loop\n","    resume_data = legacy.load_network_pkl(f)\n","  File \"/content/stylegan2-ada-pytorch/legacy.py\", line 26, in load_network_pkl\n","    G = convert_tf_generator(tf_G)\n","  File \"/content/stylegan2-ada-pytorch/legacy.py\", line 155, in convert_tf_generator\n","    raise ValueError('Unknown TensorFlow kwarg', unknown_kwargs[0])\n","ValueError: ('Unknown TensorFlow kwarg', 'resolution_h')\n"]}]}]}