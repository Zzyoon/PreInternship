{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StyleGAN_Toonify.ipynb","provenance":[{"file_id":"1CGXp8jkRxZq-jAJlNMzZbm-h9A5ZJBHu","timestamp":1644497882277},{"file_id":"1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk","timestamp":1643352815034},{"file_id":"https://github.com/dvschultz/stylegan2/blob/master/StyleGAN2_projection_interpolation.ipynb","timestamp":1598427917614}],"collapsed_sections":[],"machine_shape":"hm","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4_s8h-ilzHQc"},"source":["# Toonify yourself!\n","\n","Please ensure that you're using a GPU runtime\n","\n","First some setup:"]},{"cell_type":"code","metadata":{"id":"PzDuIoMcqfBT"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuMEHnpmI1Mj"},"source":["!git clone https://github.com/justinpinkney/stylegan2\n","%cd stylegan2\n","!nvcc test_nvcc.cu -o test_nvcc -run"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YFk46FLM9qo"},"source":["!mkdir raw\n","!mkdir aligned\n","!mkdir generated"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3IppG8Z8O19R"},"source":["## Upload your own photos\n","\n","Upload your photos to `raw/`. These don't need to be aligned as we'll use a face detector to grab all the faces and transform them into the correct format. One note of caution is that you'll need a pretty high-resolution picture of a face to get a sharp result (the final face crop is resized to 1024x1024 pixels)\n","\n","We'll grab a example image from the internet to work with.\n","\n","The basic process is:\n","- Extract faces and align the images\n","- Project the images (i.e. find the latent code)\n","- Toonify the images (i.e. use the latent code with the toon model)\n","\n","Results will be placed in the stylegan2/generated folder"]},{"cell_type":"code","metadata":{"id":"b-2oM_L8VWYZ"},"source":["# 적용시킬 얼굴\n","!wget http://monthly.chosun.com/up_fd/Mdaily/2019-05/bimg_thumb/%EB%A7%88%EB%8F%99%EC%84%9D.jpg -O raw/example.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 문제 시작\n","방법1 - invail 뭐시기 오류 발생 ; 크기가 너무 커서 url에 있는 plk파일 못 받아오는 건가??\n","방법2 - 그럼 피클 파일을 그냥 colab파일에 업로드해서 열어보자! -> module문제발생"],"metadata":{"id":"qymBuk3kuRKg"}},{"cell_type":"markdown","source":["방법1"],"metadata":{"id":"O24F2swjuNNr"}},{"cell_type":"code","metadata":{"id":"cwVXBFaSuoIU"},"source":["import pretrained_networks\n","\n","# use my copy of the blended model to save Doron's download bandwidth\n","# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n","# 원래 있던 blended_url\n","# blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\"\n","# 사용할 지브리 blended_url\n","blended_url = \"https://drive.google.com/file/d/1-l62KDZWBr8hdh6Vnf9-l-Ts3wUs5IO_/view?usp=sharing\"\n","ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n","\n"," _, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n"," _, _, Gs = pretrained_networks.load_networks(ffhq_url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pretrained_networks\n","import pickle\n","# from utils.torch_utils import select_device, time_synchronized\n","import torch_utils\n","\n","ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n","\n","# 여기서 문제 발생.. 으엑\n","with open('/content/network-snapshot-000000.pkl', 'rb') as f:\n","    loaded = pickle.load(f, encoding=\"latin1\") \n","\n"," _, _, Gs = pretrained_networks.load_networks(ffhq_url)"],"metadata":{"id":"JEJXYgb3utSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLUH060th5oQ"},"source":["!python align_images.py raw aligned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldHXNMYhnYC5"},"source":["!python project_images.py --num-steps 500 aligned generated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHQgAO2yqaew"},"source":["import numpy as np\n","from PIL import Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","from pathlib import Path\n","\n","latent_dir = Path(\"generated\")\n","latents = latent_dir.glob(\"*.npy\")\n","for latent_file in latents:\n","  latent = np.load(latent_file)\n","  latent = np.expand_dims(latent,axis=0)\n","  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n","  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n","  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcWXgS5DXata"},"source":["from IPython.display import Image \n","embedded = Image(filename=\"generated/example_01.png\", width=256)\n","display(embedded)\n","tooned = Image(filename=\"generated/example_01-toon.jpg\", width=256)\n","display(tooned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYPXfOsZpHAR"},"source":[""],"execution_count":null,"outputs":[]}]}